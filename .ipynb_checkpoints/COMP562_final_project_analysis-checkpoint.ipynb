{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP 562 Final Project Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authors:\n",
    "Cooper Lee, James Tuong, Nathaniel Turner, Alan Vasquez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "# %pip install mlxtend --quiet\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler, StandardScaler\n",
    "\n",
    "from sklearn import metrics, preprocessing\n",
    "# import sklearn #need to figure out what parts of sklearn to import that we'll use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in the dataset and splitting into test and training set (may want to do each time for the different methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = \"data/heart.csv\"\n",
    "feature_names = [\"age\",\"sex\",\"cp\",\"trtbps\",\"chol\",\"fbs\",\"restecg\",\"thalachh\",\n",
    "                                 \"exng\",\"oldpeak\",\"slp\",\"caa\",\"thall\", \"output\"]\n",
    "english_feature_names = [\"age\", \"sex\", \"chest pain\", \"resting blood pressure\", \"cholesterol\", \"fasting blood sugar\", \n",
    "                         \"resting electrocardiographic results\", \"maximum heart rate achieved\", \n",
    "                        \"exercise induced angina\", \"old peak\", \"slope\", \"number of major arteries\",\n",
    "                        \"thall rate\", \"output\"]\n",
    "cat_cols = [\"sex\",\"cp\",\"fbs\",\"restecg\", \"exng\",\"slp\",\"caa\",\"thall\"]\n",
    "con_cols = [\"age\", \"chol\",\"trtbps\",\"thalachh\",\"oldpeak\"]\n",
    "\n",
    "data = np.genfromtxt(dpath, delimiter=\",\", skip_header=1, names=feature_names)\n",
    "\n",
    "heart_data = np.array([data[i] for i in feature_names[:-1]]).T\n",
    "heart_attack_odds = data[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'con_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m scaler \u001b[38;5;241m=\u001b[39m RobustScaler()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# scaling the continuous featuree\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m X[con_cols] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X[\u001b[43mcon_cols\u001b[49m])\n\u001b[0;32m     13\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,\n\u001b[0;32m     14\u001b[0m                                                     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe shape of X_train is      \u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'con_cols' is not defined"
     ]
    }
   ],
   "source": [
    "df_tree = pd.read_csv(\"data/heart.csv\")\n",
    "df_tree = df_tree.apply(LabelEncoder().fit_transform)\n",
    "X = df_tree.drop(['output'], axis=1)\n",
    "y = df_tree['output'].values\n",
    "\n",
    "y = y.reshape(-1, 1)\n",
    "# instantiating the scaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# scaling the continuous featuree\n",
    "X[con_cols] = scaler.fit_transform(X[con_cols])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                    random_state=1, stratify=y)\n",
    "print(\"The shape of X_train is      \", X_train.shape)\n",
    "print(\"The shape of X_test is       \",X_test.shape)\n",
    "print(\"The shape of y_train is      \",y_train.shape)\n",
    "print(\"The shape of y_test is       \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nontree = pd.read_csv(\"data/heart.csv\")\n",
    "df_nontree = pd.get_dummies(df_nontree, columns = cat_cols, drop_first = True)\n",
    "X = df_nontree.drop(['output'], axis=1)\n",
    "y = df_nontree['output'].values\n",
    "\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "# instantiating the scaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# scaling the continuous featuree\n",
    "X[con_cols] = scaler.fit_transform(X[con_cols])\n",
    "\n",
    "#nontree = 'nt'\n",
    "X_train_nt, X_test_nt, y_train_nt, y_test_nt = train_test_split(X, y, test_size=0.3,\n",
    "                                                    random_state=1, stratify=y)\n",
    "print(\"The shape of X_train is      \", X_train_nt.shape)\n",
    "print(\"The shape of X_test is       \",X_test_nt.shape)\n",
    "print(\"The shape of y_train is      \",y_train_nt.shape)\n",
    "print(\"The shape of y_test is       \",y_test_nt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(feature_names)-1):\n",
    "    plt.figure()\n",
    "    plt.hist(heart_data[:,i])\n",
    "    plt.xlabel(english_feature_names[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Binary Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Accuracy log and kfold splits\n",
    "k=5\n",
    "acc_score = []\n",
    "kf = StratifiedKFold(n_splits=k)\n",
    "\n",
    "# Loop through folds\n",
    "for fold, (trn_, val_ ) in enumerate(kf.split(X_train,y_train)):\n",
    "    X_fld_train, X_fld_val = X_train.iloc[trn_,:-1], X_train.iloc[val_,:-1]\n",
    "    y_fld_train, y_fld_val= y_train[trn_], y_train[val_]\n",
    "    \n",
    "    # Create Decision Tree classifer object\n",
    "    clf_binary_tree = DecisionTreeClassifier(random_state=4, max_depth=4)\n",
    "\n",
    "    # Train Decision Tree Classifer\n",
    "    clf_binary_tree = clf_binary_tree.fit(X_fld_train,y_fld_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred_binary_tree = clf_binary_tree.predict(X_fld_val)\n",
    "    \n",
    "    #Log accuracy\n",
    "    acc = metrics.accuracy_score(y_fld_val, y_pred_binary_tree)\n",
    "    acc_score.append(acc)\n",
    "\n",
    "avg_acc_score = sum(acc_score)/k\n",
    "print('accuracy of each fold - {}'.format(acc_score))\n",
    "print('Avg accuracy : {}'.format(avg_acc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Accuracy log and kfold splits\n",
    "k=5\n",
    "acc_score = []\n",
    "kf = StratifiedKFold(n_splits=k)\n",
    "\n",
    "# Loop through folds\n",
    "for fold, (trn_, val_ ) in enumerate(kf.split(X_train,y_train)):\n",
    "    X_fld_train, X_fld_val = X_train.iloc[trn_,:-1], X_train.iloc[val_,:-1]\n",
    "    y_fld_train, y_fld_val= y_train[trn_], y_train[val_]\n",
    "    \n",
    "    # Create Random Forest Classifer object\n",
    "    forest = RandomForestClassifier(criterion='gini',\n",
    "                                 max_depth =8,\n",
    "                                 n_estimators=10,\n",
    "                                 random_state=4,\n",
    "                                 n_jobs=2)\n",
    "\n",
    "    # Train Random Forest Classifer\n",
    "    forest.fit(X_fld_train, y_fld_train.ravel())\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = forest.predict(X_fld_val)\n",
    "    \n",
    "    #Log accuracy\n",
    "    acc = accuracy_score(y_fld_val, y_pred)\n",
    "    acc_score.append(acc)\n",
    "\n",
    "avg_acc_score = sum(acc_score)/k\n",
    "print('accuracy of each fold - {}'.format(acc_score))\n",
    "print('Avg accuracy : {}'.format(avg_acc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(criterion='gini',\n",
    "                                 max_depth = 8,\n",
    "                                 n_estimators=10,\n",
    "                                 random_state=4,\n",
    "                                 n_jobs=2)\n",
    "forest.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forest.predict(X_test)\n",
    "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "#Create Accuracy log and kfold splits\n",
    "k=5\n",
    "acc_LogReg = []\n",
    "kf = StratifiedKFold(n_splits=k)\n",
    "\n",
    "# Loop through folds\n",
    "for fold, (trn_, val_ ) in enumerate(kf.split(X_train_nt,y_train_nt)):\n",
    "    X_fld_train, X_fld_val = X_train_nt.iloc[trn_,:-1], X_train_nt.iloc[val_,:-1]\n",
    "    y_fld_train, y_fld_val= y_train_nt[trn_], y_train_nt[val_]\n",
    "\n",
    "    # Create and Train  Logistic Regression Classifer\n",
    "    clf = LogisticRegression(random_state=0, max_iter=1000).fit(X_fld_train, y_fld_train.ravel())\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    clf.predict(X_fld_val)\n",
    "    clf.predict_proba(X_fld_val)\n",
    "    \n",
    "    #Log accuracy\n",
    "    acc = clf.score(X_fld_val, y_fld_val)\n",
    "    acc_LogReg.append(acc)\n",
    "\n",
    "avg_acc_score_LogReg = sum(acc_LogReg)/k\n",
    "print('accuracy of each fold - {}'.format(acc_LogReg))\n",
    "print('Avg accuracy of Logistic Regression: {}'.format(avg_acc_score_LogReg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter=800).fit(X_train_nt, y_train_nt)\n",
    "clf.predict(X_test_nt)\n",
    "\n",
    "clf.predict_proba(X_test_nt)\n",
    "\n",
    "\n",
    "clf.score(X_test_nt, y_test_nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf, X_test_nt, y_test_nt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 4: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "acc_svm=[]\n",
    "kf=StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Loop through folds\n",
    "for fold, (trn_, val_ ) in enumerate(kf.split(X_train_nt,y_train_nt)):\n",
    "    X_fld_train, X_fld_val = X_train_nt.iloc[trn_,:-1], X_train_nt.iloc[val_,:-1]\n",
    "    y_fld_train, y_fld_val= y_train_nt[trn_], y_train_nt[val_]\n",
    "    \n",
    "    ro_scaler=MinMaxScaler()\n",
    "    X_fld_train=ro_scaler.fit_transform(X_fld_train)\n",
    "    X_fld_val=ro_scaler.transform(X_fld_val)\n",
    "        \n",
    "    clf=SVC(kernel=\"rbf\")\n",
    "    clf.fit(X_fld_train, y_fld_train.ravel())\n",
    "    y_pred=clf.predict(X_fld_val)\n",
    "    acc=roc_auc_score(y_fld_val,y_pred)\n",
    "    acc_svm.append(acc)\n",
    "\n",
    "avg_acc_score_svm = sum(acc_svm)/k\n",
    "print('accuracy of each fold - {}'.format(acc_svm))\n",
    "print('Avg accuracy of Linear SVM: {}'.format(avg_acc_score_svm))\n",
    "\n",
    "#Train on entire training dataset\n",
    "ro_scaler=MinMaxScaler()\n",
    "X_train_nt=ro_scaler.fit_transform(X_train_nt)\n",
    "X_test_nt=ro_scaler.transform(X_test_nt)\n",
    "\n",
    "clf=SVC(kernel=\"linear\")\n",
    "clf.fit(X_train_nt, y_train_nt.ravel())\n",
    "y_pred=clf.predict(X_test_nt)\n",
    "print(roc_auc_score(y_test_nt,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
